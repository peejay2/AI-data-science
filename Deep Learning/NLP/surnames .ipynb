{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO5p5zI06KIcqHXtaLIs3TG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":663},"id":"vH8KNW56FcE-","executionInfo":{"status":"ok","timestamp":1688561193034,"user_tz":-120,"elapsed":59795,"user":{"displayName":"Alberto Manzi","userId":"15656457869598376802"}},"outputId":"ab599d2a-789e-4f3e-bbb4-a6a418c07f16"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a468db14-4f50-4611-b271-73d98d828fc7\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a468db14-4f50-4611-b271-73d98d828fc7\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Arabic.txt to Arabic.txt\n","Saving Chinese.txt to Chinese.txt\n","Saving Czech.txt to Czech.txt\n","Saving Dutch.txt to Dutch.txt\n","Saving English.txt to English.txt\n","Saving French.txt to French.txt\n","Saving German.txt to German.txt\n","Saving Greek.txt to Greek.txt\n","Saving Irish.txt to Irish.txt\n","Saving Italian.txt to Italian.txt\n","Saving Japanese.txt to Japanese.txt\n","Saving Korean.txt to Korean.txt\n","Saving Polish.txt to Polish.txt\n","Saving Portuguese.txt to Portuguese.txt\n","Saving Russian.txt to Russian.txt\n","Saving Scottish.txt to Scottish.txt\n","Saving Spanish.txt to Spanish.txt\n","Saving Vietnamese.txt to Vietnamese.txt\n"]}],"source":["from google.colab import files\n","\n","uploaded = files.upload()"]},{"cell_type":"code","source":[" source = \"/content/*.txt\""],"metadata":{"id":"t71uPvF0GAZE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from io import open\n","import glob\n","import os\n","import unicodedata\n","import string\n","\n","all_letters = string.ascii_letters + \" .,;'-\"\n","n_letters = len(all_letters) + 1 # Plus EOS marker\n","\n","def findFiles(path): return glob.glob(path)\n","\n","# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","        and c in all_letters\n","    )\n","\n","# Read a file and split into lines\n","def readLines(filename):\n","    with open(filename, encoding='utf-8') as some_file:\n","        return [unicodeToAscii(line.strip()) for line in some_file]\n","\n","# Build the category_lines dictionary, a list of lines per category\n","category_lines = {}\n","all_categories = []\n","for filename in findFiles(source):\n","    category = os.path.splitext(os.path.basename(filename))[0]\n","    all_categories.append(category)\n","    lines = readLines(filename)\n","    category_lines[category] = lines\n","\n","n_categories = len(all_categories)\n","\n","if n_categories == 0:\n","    raise RuntimeError('Data not found. Make sure that you downloaded data '\n","        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n","        'the current directory.')\n","\n","print('# categories:', n_categories, all_categories)\n","print(unicodeToAscii(\"O'Néàl\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7hkzuHRdFxS4","executionInfo":{"status":"ok","timestamp":1688561263070,"user_tz":-120,"elapsed":314,"user":{"displayName":"Alberto Manzi","userId":"15656457869598376802"}},"outputId":"ae41ed72-0ed1-4fb3-8452-f8d25038b607"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["# categories: 18 ['Arabic', 'Scottish', 'Portuguese', 'Dutch', 'Italian', 'Czech', 'Polish', 'Greek', 'Korean', 'Chinese', 'Irish', 'English', 'German', 'Russian', 'French', 'Spanish', 'Japanese', 'Vietnamese']\n","O'Neal\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(RNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n","        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n","        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n","        self.dropout = nn.Dropout(0.1)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, category, input, hidden):\n","        input_combined = torch.cat((category, input, hidden), 1)\n","        hidden = self.i2h(input_combined)\n","        output = self.i2o(input_combined)\n","        output_combined = torch.cat((hidden, output), 1)\n","        output = self.o2o(output_combined)\n","        output = self.dropout(output)\n","        output = self.softmax(output)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, self.hidden_size)"],"metadata":{"id":"BEu4ANI_GoCF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","# Random item from a list\n","def randomChoice(l):\n","    return l[random.randint(0, len(l) - 1)]\n","\n","# Get a random category and random line from that category\n","def randomTrainingPair():\n","    category = randomChoice(all_categories)\n","    line = randomChoice(category_lines[category])\n","    return category, line"],"metadata":{"id":"lXhSJqbyGt5t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# One-hot vector for category\n","def categoryTensor(category):\n","    li = all_categories.index(category)\n","    tensor = torch.zeros(1, n_categories)\n","    tensor[0][li] = 1\n","    return tensor\n","\n","# One-hot matrix of first to last letters (not including EOS) for input\n","def inputTensor(line):\n","    tensor = torch.zeros(len(line), 1, n_letters)\n","    for li in range(len(line)):\n","        letter = line[li]\n","        tensor[li][0][all_letters.find(letter)] = 1\n","    return tensor\n","\n","# ``LongTensor`` of second letter to end (EOS) for target\n","def targetTensor(line):\n","    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n","    letter_indexes.append(n_letters - 1) # EOS\n","    return torch.LongTensor(letter_indexes)"],"metadata":{"id":"X9mO0ZQaHW1n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make category, input, and target tensors from a random category, line pair\n","def randomTrainingExample():\n","    category, line = randomTrainingPair()\n","    category_tensor = categoryTensor(category)\n","    input_line_tensor = inputTensor(line)\n","    target_line_tensor = targetTensor(line)\n","    return category_tensor, input_line_tensor, target_line_tensor"],"metadata":{"id":"X_ByU9caIDXd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.NLLLoss()\n","\n","learning_rate = 0.0005\n","\n","def train(category_tensor, input_line_tensor, target_line_tensor):\n","    target_line_tensor.unsqueeze_(-1)\n","    hidden = rnn.initHidden()\n","\n","    rnn.zero_grad()\n","\n","    loss = torch.Tensor([0]) # you can also just simply use ``loss = 0``\n","\n","    for i in range(input_line_tensor.size(0)):\n","        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n","        l = criterion(output, target_line_tensor[i])\n","        loss += l\n","\n","    loss.backward()\n","\n","    for p in rnn.parameters():\n","        p.data.add_(p.grad.data, alpha=-learning_rate)\n","\n","    return output, loss.item() / input_line_tensor.size(0)"],"metadata":{"id":"fAoNP8l5IFAs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import math\n","\n","def timeSince(since):\n","    now = time.time()\n","    s = now - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)"],"metadata":{"id":"rn1eGV3YIG8t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rnn = RNN(n_letters, 128, n_letters)\n","\n","n_iters = 100000\n","print_every = 5000\n","plot_every = 500\n","all_losses = []\n","total_loss = 0 # Reset every ``plot_every`` ``iters``\n","\n","start = time.time()\n","\n","for iter in range(1, n_iters + 1):\n","    output, loss = train(*randomTrainingExample())\n","    total_loss += loss\n","\n","    if iter % print_every == 0:\n","        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n","\n","    if iter % plot_every == 0:\n","        all_losses.append(total_loss / plot_every)\n","        total_loss = 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3Myfz_CIJPV","executionInfo":{"status":"ok","timestamp":1688562147605,"user_tz":-120,"elapsed":329399,"user":{"displayName":"Alberto Manzi","userId":"15656457869598376802"}},"outputId":"b3234320-d9a5-485c-993f-d328153cf1db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0m 17s (5000 5%) 3.1157\n","0m 34s (10000 10%) 2.5406\n","0m 50s (15000 15%) 2.5223\n","1m 6s (20000 20%) 2.5271\n","1m 22s (25000 25%) 2.4514\n","1m 39s (30000 30%) 2.0780\n","1m 55s (35000 35%) 2.3268\n","2m 11s (40000 40%) 1.5157\n","2m 27s (45000 45%) 2.4475\n","2m 44s (50000 50%) 2.0674\n","3m 0s (55000 55%) 2.2025\n","3m 17s (60000 60%) 1.9355\n","3m 33s (65000 65%) 2.7111\n","3m 50s (70000 70%) 1.0113\n","4m 6s (75000 75%) 2.7834\n","4m 23s (80000 80%) 1.7966\n","4m 40s (85000 85%) 2.3791\n","4m 56s (90000 90%) 2.0331\n","5m 12s (95000 95%) 2.0217\n","5m 29s (100000 100%) 1.9245\n"]}]}]}